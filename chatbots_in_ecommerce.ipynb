{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m pearsonr\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfactor_analyzer\u001b[39;00m \u001b[39mimport\u001b[39;00m FactorAnalyzer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "# Filepath ist anzupassen sofern nicht auf Rechner von Pascal Jost ausgeführt wird ;)  !\n",
    "file_path = 'C:\\\\Users\\\\pasca\\\\Documents\\\\ZHAW\\\\Master\\\\ZHAW Sem 3\\\\af+e\\\\Chatbots im E-Commerce_Vollständig_Codiert.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "# Test Import erfolgreich: zeigt die ersten fünf Zeilen\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deskriptive Statistik für Ja/Nein-Fragen:\n",
      "          Frage 1     Frage 2\n",
      "count  109.000000  109.000000\n",
      "mean     1.229358    1.266055\n",
      "std      0.422362    0.443934\n",
      "min      1.000000    1.000000\n",
      "25%      1.000000    1.000000\n",
      "50%      1.000000    1.000000\n",
      "75%      1.000000    2.000000\n",
      "max      2.000000    2.000000\n",
      "\n",
      "Deskriptive Statistik für Likert-Skala-Fragen:\n",
      "          Frage 3     Frage 4     Frage 5     Frage 6     Frage 7     Frage 8   \n",
      "count  109.000000  109.000000  109.000000  109.000000  109.000000  109.000000  \\\n",
      "mean     3.431193    2.816514    3.045872    3.605505    2.577982    3.321101   \n",
      "std      1.021681    0.924613    1.030869    1.036539    1.074051    1.008122   \n",
      "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "25%      3.000000    2.000000    2.000000    3.000000    2.000000    3.000000   \n",
      "50%      4.000000    3.000000    3.000000    4.000000    2.000000    4.000000   \n",
      "75%      4.000000    3.000000    4.000000    4.000000    3.000000    4.000000   \n",
      "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
      "\n",
      "          Frage 9    Frage 10    Frage 11    Frage 12    Frage 13    Frage 14   \n",
      "count  109.000000  108.000000  109.000000  109.000000  109.000000  108.000000  \\\n",
      "mean     2.623853    2.953704    3.036697    3.073394    3.477064    2.981481   \n",
      "std      0.950526    1.342228    1.053448    1.060280    1.135262    1.032024   \n",
      "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "25%      2.000000    2.000000    2.000000    2.000000    3.000000    2.000000   \n",
      "50%      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
      "75%      3.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
      "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
      "\n",
      "         Frage 15    Frage 16    Frage 17    Frage 18  \n",
      "count  109.000000  109.000000  108.000000  109.000000  \n",
      "mean     2.082569    3.348624    2.759259    3.055046  \n",
      "std      1.081224    1.149687    1.109604    1.120804  \n",
      "min      1.000000    1.000000    1.000000    1.000000  \n",
      "25%      1.000000    3.000000    2.000000    2.000000  \n",
      "50%      2.000000    3.000000    3.000000    3.000000  \n",
      "75%      3.000000    4.000000    3.000000    4.000000  \n",
      "max      5.000000    5.000000    5.000000    5.000000  \n",
      "\n",
      "Deskriptive Statistik für demografische Fragen:\n",
      "         Frage 19    Frage 20    Frage 21\n",
      "count  109.000000  109.000000  109.000000\n",
      "mean     1.376147    1.844037    3.009174\n",
      "std      0.486655    0.747518    0.799252\n",
      "min      1.000000    1.000000    1.000000\n",
      "25%      1.000000    1.000000    3.000000\n",
      "50%      1.000000    2.000000    3.000000\n",
      "75%      2.000000    2.000000    3.000000\n",
      "max      2.000000    4.000000    5.000000\n"
     ]
    }
   ],
   "source": [
    "# Deskriptive Statistik für Ja/Nein-Fragen\n",
    "print(\"Deskriptive Statistik für Ja/Nein-Fragen:\")\n",
    "print(df[['Frage 1', 'Frage 2']].describe())\n",
    "\n",
    "# Deskriptive Statistik für Likert-Skala-Fragen\n",
    "print(\"\\nDeskriptive Statistik für Likert-Skala-Fragen:\")\n",
    "print(df.loc[:, 'Frage 3':'Frage 18'].describe())\n",
    "\n",
    "# Deskriptive Statistik für demografische Fragen\n",
    "print(\"\\nDeskriptive Statistik für demografische Fragen:\")\n",
    "print(df[['Frage 19', 'Frage 20', 'Frage 21']].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korrelationsanalyse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Performance_Expectancy_Mean   \n",
      "Performance_Expectancy_Mean                          1.000000  \\\n",
      "Effort_Expectancy_Mean                               0.419690   \n",
      "Attitude_Towards_Technology_Mean                     0.694326   \n",
      "Social_Influence_Mean                                0.394383   \n",
      "Facilitating_Conditions_Mean                         0.171115   \n",
      "Actual_Use_Mean                                      0.766269   \n",
      "\n",
      "                                  Effort_Expectancy_Mean   \n",
      "Performance_Expectancy_Mean                     0.419690  \\\n",
      "Effort_Expectancy_Mean                          1.000000   \n",
      "Attitude_Towards_Technology_Mean                0.523887   \n",
      "Social_Influence_Mean                           0.285681   \n",
      "Facilitating_Conditions_Mean                    0.400641   \n",
      "Actual_Use_Mean                                 0.389507   \n",
      "\n",
      "                                  Attitude_Towards_Technology_Mean   \n",
      "Performance_Expectancy_Mean                               0.694326  \\\n",
      "Effort_Expectancy_Mean                                    0.523887   \n",
      "Attitude_Towards_Technology_Mean                          1.000000   \n",
      "Social_Influence_Mean                                     0.423923   \n",
      "Facilitating_Conditions_Mean                              0.266014   \n",
      "Actual_Use_Mean                                           0.781697   \n",
      "\n",
      "                                  Social_Influence_Mean   \n",
      "Performance_Expectancy_Mean                    0.394383  \\\n",
      "Effort_Expectancy_Mean                         0.285681   \n",
      "Attitude_Towards_Technology_Mean               0.423923   \n",
      "Social_Influence_Mean                          1.000000   \n",
      "Facilitating_Conditions_Mean                  -0.057485   \n",
      "Actual_Use_Mean                                0.452825   \n",
      "\n",
      "                                  Facilitating_Conditions_Mean   \n",
      "Performance_Expectancy_Mean                           0.171115  \\\n",
      "Effort_Expectancy_Mean                                0.400641   \n",
      "Attitude_Towards_Technology_Mean                      0.266014   \n",
      "Social_Influence_Mean                                -0.057485   \n",
      "Facilitating_Conditions_Mean                          1.000000   \n",
      "Actual_Use_Mean                                       0.222215   \n",
      "\n",
      "                                  Actual_Use_Mean  \n",
      "Performance_Expectancy_Mean              0.766269  \n",
      "Effort_Expectancy_Mean                   0.389507  \n",
      "Attitude_Towards_Technology_Mean         0.781697  \n",
      "Social_Influence_Mean                    0.452825  \n",
      "Facilitating_Conditions_Mean             0.222215  \n",
      "Actual_Use_Mean                          1.000000  \n",
      "Pearson-Korrelation zwischen Leistungserwartung und tatsächlicher Nutzung: 0.7662691589545203, p-Wert: 2.772964028495513e-22\n"
     ]
    }
   ],
   "source": [
    "# Invertieren der Skalen für die negativ formulierten Fragen\n",
    "df['Frage5_inverted']  = 6 - df['Frage 5']\n",
    "df['Frage7_inverted']  = 6 - df['Frage 7']\n",
    "df['Frage10_inverted'] = 6 - df['Frage 10']\n",
    "df['Frage13_inverted'] = 6 - df['Frage 13']\n",
    "df['Frage15_inverted'] = 6 - df['Frage 15']\n",
    "df['Frage18_inverted'] = 6 - df['Frage 18']\n",
    "\n",
    "# Berechnung der Mittelwerte für jede UTAUT-Dimension unter Berücksichtigung der invertierten Skalen\n",
    "performance_expectancy = df[['Frage 3', 'Frage 4', 'Frage5_inverted']].mean(axis=1)\n",
    "effort_expectancy = df[['Frage 6', 'Frage7_inverted']].mean(axis=1)\n",
    "attitude_towards_technology = df[['Frage 8', 'Frage 9', 'Frage10_inverted']].mean(axis=1)\n",
    "social_influence = df[['Frage 11', 'Frage 12', 'Frage13_inverted']].mean(axis=1)\n",
    "facilitating_conditions = df[['Frage 14', 'Frage15_inverted', 'Frage 16']].mean(axis=1)\n",
    "actual_use = df[['Frage 17', 'Frage18_inverted']].mean(axis=1)\n",
    "\n",
    "# Mittelwerte als separate Spalten in den DataFrame einfügen\n",
    "df['Performance_Expectancy_Mean'] = performance_expectancy\n",
    "df['Effort_Expectancy_Mean'] = effort_expectancy\n",
    "df['Attitude_Towards_Technology_Mean'] = attitude_towards_technology\n",
    "df['Social_Influence_Mean'] = social_influence\n",
    "df['Facilitating_Conditions_Mean'] = facilitating_conditions\n",
    "df['Actual_Use_Mean'] = actual_use\n",
    "\n",
    "# Berechnung der Korrelationsmatrix\n",
    "correlation_matrix = df[['Performance_Expectancy_Mean', 'Effort_Expectancy_Mean', \n",
    "                         'Attitude_Towards_Technology_Mean', 'Social_Influence_Mean', \n",
    "                         'Facilitating_Conditions_Mean', 'Actual_Use_Mean']].corr()\n",
    "\n",
    "# Anzeigen der Korrelationsmatrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Spezifische Pearson-Korrelation zwischen einer UTAUT-Dimension und der tatsächlichen Nutzung\n",
    "pearson_corr, p_value = pearsonr(df['Performance_Expectancy_Mean'], df['Actual_Use_Mean'])\n",
    "print(f'Pearson-Korrelation zwischen Leistungserwartung und tatsächlicher Nutzung: {pearson_corr}, p-Wert: {p_value}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reliabilitätsanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6270241394277318,\n",
       " 0.659168754153673,\n",
       " 0.7169100474250565,\n",
       " 0.8312153270545736,\n",
       " 0.6064962274504148,\n",
       " 0.7946841226132526)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invertieren der Skalen für die negativ formulierten Fragen\n",
    "df['Frage5_inverted']  = 6 - df['Frage 5']\n",
    "df['Frage7_inverted']  = 6 - df['Frage 7']\n",
    "df['Frage10_inverted'] = 6 - df['Frage 10']\n",
    "df['Frage13_inverted'] = 6 - df['Frage 13']\n",
    "df['Frage15_inverted'] = 6 - df['Frage 15']\n",
    "df['Frage18_inverted'] = 6 - df['Frage 18']\n",
    "\n",
    "# Funktion zur Berechnung von Cronbachs Alpha\n",
    "def cronbach_alpha(df_items):\n",
    "    # Anzahl der Items\n",
    "    items_count = df_items.shape[1]\n",
    "    \n",
    "    # Gesamtvarianz der summierten Items\n",
    "    total_var = df_items.sum(axis=1).var(ddof=1)\n",
    "    \n",
    "    # Summe der Varianzen der einzelnen Items\n",
    "    variances_sum = df_items.var(axis=0, ddof=1).sum()\n",
    "    \n",
    "    # Berechnung von Cronbachs Alpha\n",
    "    alpha = (items_count / float(items_count - 1)) * (1 - (variances_sum / total_var))\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "# Berechnung von Cronbachs Alpha für jede UTAUT-Dimension\n",
    "performance_expectancy_alpha = cronbach_alpha(df[['Frage 3', 'Frage 4', 'Frage5_inverted']])\n",
    "effort_expectancy_alpha = cronbach_alpha(df[['Frage 6', 'Frage7_inverted']])\n",
    "attitude_towards_technology_alpha = cronbach_alpha(df[['Frage 8', 'Frage 9', 'Frage10_inverted']])\n",
    "social_influence_alpha = cronbach_alpha(df[['Frage 11', 'Frage 12', 'Frage13_inverted']])\n",
    "facilitating_conditions_alpha = cronbach_alpha(df[['Frage 14', 'Frage15_inverted', 'Frage 16']])\n",
    "actual_use_alpha = cronbach_alpha(df[['Frage 17', 'Frage18_inverted']])\n",
    "\n",
    "# Ausgabe der Cronbachs Alpha Werte für jede Dimension\n",
    "(performance_expectancy_alpha, effort_expectancy_alpha, attitude_towards_technology_alpha, \n",
    " social_influence_alpha, facilitating_conditions_alpha, actual_use_alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse negativer Wert bei Effort Expectancy aus der Reliabilitätsanalyse\n",
    "Finding: Frage 7 wurde vergessen zu Invertieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Frage 6   Frage 7\n",
      "Frage 6  1.000000 -0.491923\n",
      "Frage 7 -0.491923  1.000000\n",
      "Frage 6    0.477497\n",
      "Frage 7    0.530081\n",
      "dtype: float64\n",
      "          Frage 6     Frage 7\n",
      "count  109.000000  109.000000\n",
      "mean     3.605505    2.577982\n",
      "std      1.036539    1.074051\n",
      "min      1.000000    1.000000\n",
      "25%      3.000000    2.000000\n",
      "50%      4.000000    2.000000\n",
      "75%      4.000000    3.000000\n",
      "max      5.000000    5.000000\n",
      "   Frage 6  Frage 7\n",
      "0        4        2\n",
      "1        5        1\n",
      "2        5        2\n",
      "3        5        2\n",
      "4        4        4\n"
     ]
    }
   ],
   "source": [
    "# Korrelationsmatrix der Items in der \"Effort Expectancy\"-Dimension\n",
    "effort_expectancy_corr = df[['Frage 6', 'Frage 7']].corr()\n",
    "print(effort_expectancy_corr)\n",
    "\n",
    "# Berechnung der Item-Total-Korrelation für die \"Effort Expectancy\"-Dimension\n",
    "effort_expectancy_total_corr = df[['Frage 6', 'Frage 7']].corrwith(df[['Frage 6', 'Frage 7']].sum(axis=1))\n",
    "print(effort_expectancy_total_corr)\n",
    "\n",
    "# Deskriptive Statistiken für die \"Effort Expectancy\"-Dimension\n",
    "effort_expectancy_descriptive = df[['Frage 6', 'Frage 7']].describe()\n",
    "print(effort_expectancy_descriptive)\n",
    "\n",
    "# Überprüfen Sie die Skalierung der Fragen\n",
    "print(df[['Frage 6', 'Frage 7']].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse ungenügende Werte aus der Reliabilitätsanalyse\n",
    "-- Verzicht aufgrund Anzahl Items - Fokus auf weitere Analysen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faktorenanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: factor-analyzer in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from factor-analyzer) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from factor-analyzer) (1.24.2)\n",
      "Requirement already satisfied: pre-commit in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from factor-analyzer) (3.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from factor-analyzer) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from factor-analyzer) (1.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from matplotlib) (4.39.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pandas->factor-analyzer) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pandas->factor-analyzer) (2022.7)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pre-commit->factor-analyzer) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pre-commit->factor-analyzer) (20.25.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pre-commit->factor-analyzer) (2.5.33)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pre-commit->factor-analyzer) (6.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from pre-commit->factor-analyzer) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from scikit-learn->factor-analyzer) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from scikit-learn->factor-analyzer) (3.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from nodeenv>=0.11.1->pre-commit->factor-analyzer) (65.6.3)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit->factor-analyzer) (0.3.8)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit->factor-analyzer) (4.1.0)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit->factor-analyzer) (3.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.2-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-win_amd64.whl (186 kB)\n",
      "Collecting numpy<2,>=1.21\n",
      "  Using cached numpy-1.26.3-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.47.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-10.2.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, contourpy, matplotlib\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.1\n",
      "    Uninstalling pyparsing-3.1.1:\n",
      "      Successfully uninstalled pyparsing-3.1.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Zugriff verweigert: 'C:\\\\Users\\\\pasca\\\\anaconda3\\\\envs\\\\adsenv\\\\Lib\\\\site-packages\\\\numpy\\\\~ore\\\\_multiarray_tests.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall --upgrade --force-reinstall matplotlib\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfactor_analyzer\u001b[39;00m \u001b[39mimport\u001b[39;00m FactorAnalyzer\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# Laden der Daten\u001b[39;00m\n\u001b[0;32m      9\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mpasca\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDocuments\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mZHAW\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mMaster\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mZHAW Sem 3\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39maf+e\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mChatbots im E-Commerce_Vollständig_Codiert.xlsx\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%pip install factor-analyzer matplotlib\n",
    "%pip install --upgrade --force-reinstall matplotlib\n",
    "\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Laden der Daten\n",
    "file_path = 'C:\\\\Users\\\\pasca\\\\Documents\\\\ZHAW\\\\Master\\\\ZHAW Sem 3\\\\af+e\\\\Chatbots im E-Commerce_Vollständig_Codiert.xlsx'\n",
    "\n",
    "# Invertierung negativer Items, falls erforderlich\n",
    "df['Frage5_inverted']  = 6 - df['Frage 5']\n",
    "df['Frage7_inverted']  = 6 - df['Frage 7']\n",
    "df['Frage10_inverted'] = 6 - df['Frage 10']\n",
    "df['Frage13_inverted'] = 6 - df['Frage 13']\n",
    "df['Frage15_inverted'] = 6 - df['Frage 15']\n",
    "df['Frage18_inverted'] = 6 - df['Frage 18']\n",
    "\n",
    "# Auswahl der Likert-Skala-Fragen für die Faktorenanalyse\n",
    "likert_items = df[['Frage 3', 'Frage 4', 'Frage 5_inverted', 'Frage 6', 'Frage7_inverted', 'Frage 8', 'Frage 9', 'Frage10_inverted',\n",
    "                   'Frage 11', 'Frage 12', 'Frage13_inverted', 'Frage 14', 'Frage15_inverted', 'Frage 16', 'Frage 17', 'Frage18_inverted']]  # Fügen Sie alle relevanten Fragen hinzu\n",
    "\n",
    "# Faktorenanalyse\n",
    "fa = FactorAnalyzer(rotation='varimax')\n",
    "\n",
    "# Bestimmung der Anzahl der Faktoren\n",
    "fa.set_params(n_factors=6, method='principal')\n",
    "fa.fit(likert_items)\n",
    "\n",
    "# Laden der Faktoren\n",
    "factor_loadings = fa.loadings_\n",
    "\n",
    "# Scree-Plot zur visuellen Überprüfung der Faktorenanzahl\n",
    "plt.scatter(range(1, likert_items.shape[1]+1), fa.get_eigenvalues()[0])\n",
    "plt.plot(range(1, likert_items.shape[1]+1), fa.get_eigenvalues()[0])\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Faktoren')\n",
    "plt.ylabel('Eigenwert')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Ausgabe der Faktorladungen\n",
    "print(factor_loadings)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PE_Mean', 'EE_Mean', 'SI_Mean', 'FC_Mean', 'Education_schoolEducation_apprenticeship'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mEducation_no_answer\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mFrage 21\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mkeine Angabe Ausbildung\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[39m# Unabhängige Variablen und Moderatoren\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m X \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39;49m\u001b[39mPE_Mean\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mEE_Mean\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSI_Mean\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFC_Mean\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAge_14-29\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAge_30-54\u001b[39;49m\u001b[39m'\u001b[39;49m , \u001b[39m'\u001b[39;49m\u001b[39mAge_55_and_more\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAge_no_answer\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mGender_Male\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mGender_Female\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mEducation_school\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     29\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mEducation_apprenticeship\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mEducation_university_applied_science\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mEducation_university\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mEducation_no_answer\u001b[39;49m\u001b[39m'\u001b[39;49m ]]\n\u001b[0;32m     31\u001b[0m \u001b[39m# Abhängige Variable für Nutzungsabsicht (BI)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m y_bi \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mBI_Mean\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pasca\\anaconda3\\envs\\adsenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PE_Mean', 'EE_Mean', 'SI_Mean', 'FC_Mean', 'Education_schoolEducation_apprenticeship'] not in index\""
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Berechnung der Mittelwerte für jede UTAUT-Dimension unter Berücksichtigung der invertierten Skalen\n",
    "PE_Mean = df[['Frage 3', 'Frage 4', 'Frage5_inverted']].mean(axis=1)\n",
    "EE_Mean = df[['Frage 6', 'Frage7_inverted']].mean(axis=1)\n",
    "attitude_towards_technology = df[['Frage 8', 'Frage 9', 'Frage10_inverted']].mean(axis=1)\n",
    "SI_Mean = df[['Frage 11', 'Frage 12', 'Frage13_inverted']].mean(axis=1)\n",
    "FC_Mean = df[['Frage 14', 'Frage15_inverted', 'Frage 16']].mean(axis=1)\n",
    "actual_use = df[['Frage 17', 'Frage18_inverted']].mean(axis=1)\n",
    "\n",
    "\n",
    "# Dummy-Variablen für kategoriale Daten erstellen\n",
    "df['Gender_Male'] = df['Frage 19'].apply(lambda x: 1 if x == 'Männlich' else 0)\n",
    "df['Gender_Female'] = df['Frage 19'].apply(lambda x: 1 if x == 'Weiblich' else 0)\n",
    "\n",
    "df['Age_14-29'] = df['Frage 20'].apply(lambda x: 1 if x == '14-29' else 0)\n",
    "df['Age_30-54'] = df['Frage 20'].apply(lambda x: 1 if x == '30-54' else 0)\n",
    "df['Age_55_and_more'] = df['Frage 20'].apply(lambda x: 1 if x == '55+' else 0)\n",
    "df['Age_no_answer'] = df['Frage 20'].apply(lambda x: 1 if x == 'keine Angabe Alter' else 0)\n",
    "\n",
    "df['Education_school'] = df['Frage 21'].apply(lambda x: 1 if x == 'Oblig. Schule' else 0)\n",
    "df['Education_apprenticeship'] = df['Frage 21'].apply(lambda x: 1 if x == 'Berufslehre' else 0)\n",
    "df['Education_university_applied_science'] = df['Frage 21'].apply(lambda x: 1 if x == 'Fachhochschule' else 0)\n",
    "df['Education_university'] = df['Frage 21'].apply(lambda x: 1 if x == 'Universität' else 0)\n",
    "df['Education_no_answer'] = df['Frage 21'].apply(lambda x: 1 if x == 'keine Angabe Ausbildung' else 0)\n",
    "\n",
    "# Unabhängige Variablen und Moderatoren\n",
    "X = df[['PE_Mean', 'EE_Mean', 'SI_Mean', 'FC_Mean', 'Age_14-29', 'Age_30-54' , 'Age_55_and_more', 'Age_no_answer', 'Gender_Male', 'Gender_Female', 'Education_school'\n",
    "        'Education_apprenticeship', 'Education_university_applied_science', 'Education_university', 'Education_no_answer' ]]\n",
    "\n",
    "# Abhängige Variable für Nutzungsabsicht (BI)\n",
    "y_bi = df['BI_Mean']\n",
    "\n",
    "# Modell für Nutzungsabsicht\n",
    "X_bi = sm.add_constant(X)\n",
    "model_bi = sm.OLS(y_bi, X_bi).fit()\n",
    "print(model_bi.summary())\n",
    "\n",
    "# Abhängige Variable für tatsächliche Nutzung (UB)\n",
    "y_ub = df['UB_Mean']\n",
    "\n",
    "# Modell für tatsächliche Nutzung\n",
    "X_ub = sm.add_constant(X)\n",
    "model_ub = sm.OLS(y_ub, X_ub).fit()\n",
    "print(model_ub.summary())\n",
    "\n",
    "\n",
    "# Beispiel für eine multiple Regression\n",
    "X = df[['Performance_Expectancy_Mean', 'Effort_Expectancy_Mean', ...]]  # Unabhängige Variablen\n",
    "y = df['Actual_Use_Mean']  # Abhängige Variable\n",
    "X = sm.add_constant(X)  # Fügt eine Konstante hinzu\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-Tests (für zwei Gruppen) und ANOVAs (für mehrere Gruppen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Beispiel für einen T-Test\n",
    "group1 = df[df['Geschlecht'] == 1]['Actual_Use_Mean']  # Männlich\n",
    "group2 = df[df['Geschlecht'] == 2]['Actual_Use_Mean']  # Weiblich\n",
    "\n",
    "t_statistic, p_value = ttest_ind(group1, group2)\n",
    "print(t_statistic, p_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a37b286354bbfa49b681235477156423a78583b7807841e2526717de7ee72f3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
